---
title: "Power calculations"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: united
    highlight: tango
    code_folding: hide
params:
  author: "Ben Jaques-Leslie"
  project_number: 2233
  project_name: "USWDS Digital Dashboard"
  data_folder: "G:/Shared drives/MSG Projects/3.0 Digital Government (LQ3)/2233 USWDS Digital Dashboard/03. Data Collection"
  data: "wds.rdata"
  sample_min: 100
  sample_max: 2000
  ate: -1
  ate_min: -10
  ate_max: -1
  ate_increment: 1
  error_variance: .45
  treatment_probability: .5
  panels_min: 1
  panels_max: 4
  treatment_at_min: 1
  treatment_at_max: 4
  simulations: 100
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(skimr)
library(DataExplorer)
library(readr)
# library(oesrrr)
# library(oescolorrrs)
library(ggthemes)
library(DesignLibrary)
library(MASS)
library(flextable)
```

# Power calculations {.tabset .tabset-pills}

**Project number**: `r params$project_number`

**Project name**: `r params$project_name`

**Author**: `r params$author`

**Data**: `r params$data`'

## Load data {.tabset .tabset-pills}

### Data from `r params$data`

```{r}
load(file.path(params$data_folder,params$data))
```

Review data.

```{r}
d %>% skim()
```

Review the data by outcome and treatment.

```{r}
d %>% group_by(name) %>%  skim()
```

## Understanding the outcome distribution {.tabset .tabset-pills}

### Overall distribution of issues.

Issues are very left skewed. This drops null values, which may not be the right choice.

```{r}
d %>%
  filter(name != "uswds_score") %>%
  ggplot(aes(x = value)) +
  geom_density() +
  theme_fivethirtyeight() +
  scale_fill_oes()
```

### Distribution by issue count and WDS score.

Again issues are very left skewed. This is consistent across the issue types. WDS score is really an indicator.

```{r}
d %>%
  ggplot(aes(x = value, fill = name)) +
  geom_histogram() +
  scale_fill_oes(palette = "full colors") +
  theme_fivethirtyeight()
```

When we treat the null values as zero, we have greater skew.

```{r}
d %>%
  mutate(value = replace_na(value, 0)) %>%
  ggplot(aes(x = value, fill = name)) +
  geom_histogram() +
  scale_fill_oes(palette = "full colors") +
  theme_fivethirtyeight() +
  facet_wrap('name', scales = "free")
```

Outcome distribution is very left skewed and may be better model by a negative binomial distribution.
<!--
JB: If this is a randomized trial then we don't need to choose a model of the
outcome. See Chapter 3 of Gerber and Green field experiments or the materials on
estimation in https://egap.github.io/theory_and_practice_of_field_experiments/

-->

## Power analysis {.tabset .tabset-pills}

### Assumptions

Several assumptions are based on the means and sample size of the USWDS data.
<!--
https://english.stackexchange.com/questions/15081/based-on-instead-of-based-off-of
-->

```{r}
prep_01 <-
  d %>%
  group_by(name) %>%
  summarise(mean = mean(value, na.rm = TRUE),
            websites = n_distinct(website)) %>%
  ungroup()

prep_01
```

Using the color contrast issues count as the primary outcome of interest. The assumed population mean is the mean issues.

```{r}
population_mean_color_contrast_issues <-
  prep_01 %>%
  filter(name == "color_contrast_issues") %>%
  pull(mean)

population_mean_color_contrast_issues
```

The populations size is the number of websites measured for color contrast issues.

```{r}
population_size_color_contrast_issues <-
  prep_01 %>%
  filter(name == "color_contrast_issues") %>%
  pull(websites)

population_size_color_contrast_issues
```

The proportion treated is the proportion of screened websites that have the USWDS indicator.

```{r}
population_treatement_proportion <-
  d %>%
  filter(name == "uswds_score") %>%
  filter(value == 100) %>%
  summarise(websites = n_distinct(website)) %>%
  pull(websites)/population_size_color_contrast_issues

population_treatement_proportion
```

The assumed average treatment effect is between `r params$ate_min` and `r params$ate_max`. We are assuming that the use of USWDS will decrease the number of issues by between `r params$ate_min` and `r params$ate_max`.

Based on the evaluation of the outcome indicators above, we are assuming that the outcome indicators follow a negative binomial distribution, but cannot fall below zero.

The treatment effect is likely to come from a negative binomial distribution on the left side of zero as the treatment is unlikely to increase issues and follow a similar distribution to the outcome.

We calculate the treatment effect with this formula:

$$
Y_1 = \beta_0 + \beta_1Treatment
$$

$Y_1$ is calculated by the number of issues or by the rank of the agency in number of issues. 

### Functions

The function below calculates the betas based on the assumptions above.

```{r}
simulation_01 <- function(
    in_iteration,
    in_population_size,
    in_ate,
    in_population_mean,
    in_prop_assigned_treatment
    )
{
  # Treatment effect
  effect <- -rnbinom(in_population_size, size = 1, mu = -in_ate)

  # Outcome distribution
  outcome_0 <- rnbinom(in_population_size, size = 1, mu = in_population_mean)

  # Simulated data
  pop_01 <- fabricate(
  N = in_population_size,
  effect = effect,
  treatment = complete_ra(N = in_population_size,prob = in_prop_assigned_treatment),
  outcome_0 = outcome_0,
  outcome_1 = case_when(
    effect*treatment + outcome_0 < 0 ~ 0,
    effect*treatment + outcome_0 >= 0 ~ effect*treatment + outcome_0
  ),
  outcome_obs = treatment*outcome_1 + (1-treatment)*outcome_0
)


  # Not doing covariance adjustment using baseline outcome_0 because it basically perfectly predicts observed outcome given rareness of treatment. Maybe create another baseline outcome that is not a perfect predictor of outcome_obs.
  reg <-
  pop_01 %>% lm_robust(outcome_obs ~ treatment, data = .)
  
  # This next does not estimate the average number of outcome caused by treatment
  # but the p-value is a test with power against the alternative that the treatment group is *higher* than the control group (ranks bigger on average). It estimate the average difference in ranks.
  
  pop_01$outcome_obs_rank <- rank(pop_01$outcome_obs)
  rank_reg <- lm_robust(outcome_obs_rank~treatment,data=pop_01)
  
  # Tidying regressions
  
  prep_01 <- 
    reg %>%
    tidy() %>%
    mutate(iteration = as.character(in_iteration),
           regression = "outcome") %>%
    dplyr::select(iteration, everything())
  
   prep_02 <- 
    rank_reg %>%
    tidy() %>%
    mutate(iteration = as.character(in_iteration),
           regression = "rank") %>%
    dplyr::select(iteration, everything())

  out <- bind_rows(prep_01,prep_02)

  return(out)
}
```

This functions calculates the power of different average treatment effects for specified number of simulations.

```{r}
power_01 <- function(in_iterations,
              in_population_size,
              in_ate,
              in_population_mean,
              in_prop_assigned_treatment)
{
  sims <-
  1:in_iterations %>%
  map_dfr(~simulation_01(in_iteration = .,
              in_population_size = in_population_size, # population_size_color_contrast_issues,
              in_ate = in_ate,
              in_population_mean = in_population_mean , #population_mean_color_contrast_issues,
              in_prop_assigned_treatment = in_prop_assigned_treatment #population_treatement_proportion,
              )
  )
  
  out <- 
    sims %>% 
  filter(term=="treatment") %>%
  group_by(regression) %>%
  summarise(beta_mean = mean(estimate),
            beta_sd = sd(estimate),
            power = mean(p.value <= 0.05)) %>% 
    ungroup() %>% 
    mutate(ate = in_ate)
  
  return(out)
}
```

### Calculating power

We calculate the power for treatment effects between `r params$ate_min` and `r params$ate_max` incremented by `r params$ate_increment` for `r scales::comma(params$simulations)` of this function.

```{r}
powers <-
  seq(params$ate_min,params$ate_max, params$ate_increment) %>%
  map_dfr(~power_01(in_iteration = params$simulations,
              in_population_size = population_size_color_contrast_issues, # population_size_color_contrast_issues,
              in_ate = .,
              in_population_mean = population_mean_color_contrast_issues , #population_mean_color_contrast_issues,
              in_prop_assigned_treatment = population_treatement_proportion #population_treatement_proportion,
              )
  )
```

### Minimum detectable effect

The chart below shows the power for different average treatment effects.

```{r}
powers %>% 
  ggplot(aes(x = ate, y = power, color = regression)) +
  geom_line() +
  geom_hline(yintercept = .8) +
  ggthemes::theme_fivethirtyeight() +
  scale_x_continuous(limits = c(params$ate_min,params$ate_max),
                     breaks = seq(params$ate_min,params$ate_max, params$ate_increment)) +
  # scale_color_oes() +
  # scale_fill_oes() +
  labs(
    title = "Power at different effects levels",
    subtitle = glue::glue("Population size: {scales::comma(population_size_color_contrast_issues)}
                          Population outcome mean: {scales::comma(population_mean_color_contrast_issues, accuracy = .01)}
                          Population treatment proportion: {scales::comma(population_treatement_proportion, accuracy = .01)}
                          Number of simulations: {scales::comma(params$simulations)}
                          ")
    
  ) +
  xlab("Average treatment effect") +
  ylab("Power") +
  theme(
    axis.title = element_text(),
    legend.title = element_blank(),
    legend.position = "right",
    legend.direction = "vertical",
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5,
                                 size = 10)
  )
```

```{r}
tbl <- powers %>% 
  filter(power >= .8) %>% 
  group_by(regression) %>% 
  filter(power == min(power)) %>% 
           ungroup() %>% 
    dplyr::select(regression, power, ate) %>% 
  mutate(regression = str_to_title(regression)) %>% 
  rename_all(~str_to_title(.)) %>% 
  rename("Minimum detectable effect" = Ate) 

tbl
```

```{r}
tbl %>% 
  flextable() %>% 
  autofit()
  
```

